---
title: 'G-RIPS Research Musing #3'
date: 2023-06-29
permalink: /posts/2023/06/grips-post-3/
tags:
  - g-rips 2023
  - statistical shape modeling
  - neural networks
---


Beginning work on a miniproject based on reading the research of Marcel LÃ¼thi and Thomas Gerig on [Gaussian process morphable models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8010438). Their GPMMs are an expansion of the classical point distribution models. Given a set of shapes in space $\{\Gamma_1,\dots,\Gamma_n\}$, they set one shape as the reference shape and the consider the deformation fields $u_i$, which are vector fields from $\mathbb{R^3} \rightarrow \mathbb{R^3}$ such that for any shape $\Gamma_i$ there exists a deformation $u_i$ such that $\Gamma_i(x) = \{\bar{x}+u(x)|\}$.

If we model all the example shapes in our data set as being generated by a normal process, $\Gamma_i \sim N(\mu, \Sigma)$, then we can model the deformations as a Gaussian process, since the instantation of any one deformation is another shape, hence a realized normal process - $u_i \sim GP(0,k)$, where $k$ is our kernel function.

We can perform PCA to rewrite the shapes as polynomials in the eigenvectors and eigenvalues of the covariance matrix, which helps with obtaining a low-rank representation. We can also do this for the deformations by considering the eigenfunctions of the operator $T_k f(x) = \int k(\cdot,x)f(x) d\rho(x)$. Then the deformations can be written as $u_i(x) = \mu(x) + \sum^{\infty} \beta_i \sqrt{\lambda_i}\phi_i(x)$.

[Yang and Tokdar (2015)](https://arxiv.org/abs/1401.7278) present results showing that Gaussian process regression is near-minimax optimal for estimations of additive functions with potentially varying sparsities, and provide an estimate for the minimax risk in terms of the entropy number of the function space containing the class of functions to be estimated. In particular, and unsurprisingly, it turns out to depend on the smoothness of the functions. Because our functions are deformations on the space of anatomical shapes, I think that applying Yang and Tokdar would yield excellent results in terms of constraining the minimax risk of such a GP-regression.

[Rosasco, Belkin & de Vito (2010)](https://dl.acm.org/doi/10.5555/1756006.1756036) describe how to get bounds on eigenfunctions of integral operators, and that, in particular, they can be identified with the eigenvectors of the kernel very easily. [Steinwart and Fischer (2019)](https://arxiv.org/pdf/1912.11741.pdf) provide derivations of the entropy numbers of Gaussian kernels which I can hopefully use to derive the Yang-Tokdar estimates.

More to come!
